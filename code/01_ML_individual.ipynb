{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "\n",
    "\n",
    "# temporal resolution: \"W\" for weekly, or \"M\" for monthly\n",
    "freq = \"W\"\n",
    "\n",
    "# The number of decision trees in Random Forest ensemble\n",
    "n_trees = 10 # recommended: 100\n",
    "\n",
    "# to subset only June, July, August, and September: True\n",
    "# to consider all available TSL measurements: False\n",
    "subset_jjas = False\n",
    "\n",
    "# to consider only mean temperature: True\n",
    "# to consider mean, min, max temperatures: False\n",
    "only_t2m_mean = True\n",
    "\n",
    "if freq == \"M\":\n",
    "    freq_prefix = \"monthly\"\n",
    "elif freq == \"W\":\n",
    "    freq_prefix = \"weekly\"\n",
    "\n",
    "if subset_jjas:\n",
    "    subset_prefix = \"JJAS\"\n",
    "else:\n",
    "    subset_prefix = \"full\"\n",
    "\n",
    "# Dir for results\n",
    "results_path = f\"../results/{freq_prefix}_{subset_prefix}/\"\n",
    "results_path_models = f\"../results/{freq_prefix}_{subset_prefix}/trained_models/\"\n",
    "results_path_simulations = f\"../results/{freq_prefix}_{subset_prefix}/simulations/\"\n",
    "\n",
    "if not os.path.exists(results_path):\n",
    "    os.mkdir(results_path)\n",
    "if not os.path.exists(results_path_models):\n",
    "    os.mkdir(results_path_models)\n",
    "if not os.path.exists(results_path_simulations):\n",
    "    os.mkdir(results_path_simulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining sources of data\n",
    "\n",
    "# RGI IDs\n",
    "glacier_ids = np.load(\"../data/misc/glacier_IDs.npy\", allow_pickle=True)\n",
    "\n",
    "# TSLs\n",
    "tsl_store = pd.read_pickle(\"../data/tsl/TSLs.pkl\")\n",
    "\n",
    "# Meteo forcing\n",
    "meteo_path = \"../data/meteo/agg-weekly/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tsl(rgi_id, store=tsl_store):\n",
    "    \n",
    "    tsl = tsl_store[tsl_store['RGI_ID'] == rgi_id].copy()\n",
    "    \n",
    "    tsl.index = pd.to_datetime(tsl['LS_DATE'])\n",
    "    \n",
    "    tsl = pd.DataFrame(tsl['TSL_m'])    \n",
    "    \n",
    "    return tsl\n",
    "\n",
    "def read_meteo(rgi_id, path=meteo_path):\n",
    "    \n",
    "    meteo = pd.read_hdf(f\"{meteo_path}{rgi_id}.h5\")\n",
    "    meteo.index = pd.to_datetime(meteo['date'])\n",
    "    meteo = meteo.drop(['date', 'wind_dir_mean_labels'], axis=1)\n",
    "    \n",
    "    return meteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(dataframe, back_to=12):\n",
    "    \n",
    "    # convert circular wind_dir_mean \n",
    "    # to two components of cos() and sin()\n",
    "    # source: https://stats.stackexchange.com/questions/336613/\n",
    "    # regression-using-circular-variable-hour-from-023-as-predictor\n",
    "    \n",
    "    # copy for safety\n",
    "    df = dataframe.copy()\n",
    "    \n",
    "    # create cos() and sin() components\n",
    "    df[\"wind_dir_mean_cos\"] = np.cos(np.deg2rad(df[\"wind_dir_mean\"]))\n",
    "    df[\"wind_dir_mean_sin\"] = np.sin(np.deg2rad(df[\"wind_dir_mean\"]))\n",
    "    \n",
    "    # drop \"wind_dir_mean\"\n",
    "    df = df.drop([\"wind_dir_mean\"], axis=1)\n",
    "    \n",
    "    # make shifts and rolling means\n",
    "    cols = df.columns\n",
    "    for col in cols:\n",
    "        for shift in range(1, back_to+1, 1):\n",
    "            df[\"{}-{}\".format(col, shift)] = df[col].shift(shift).values\n",
    "        for rol in range(1, back_to+1, 1):\n",
    "            df[\"{}rol-{}\".format(col, rol)] = df[col].rolling(window=rol).mean().values\n",
    "    \n",
    "    # delete NaNs\n",
    "    df = df.dropna()\n",
    "       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_construction(rgi_id, freq, subset_jjas, only_t2m_mean):\n",
    "    \n",
    "    # get raw TSL measurements\n",
    "    tsl = read_tsl(rgi_id)\n",
    "    \n",
    "    # resample to specific frequency\n",
    "    tsl_resample = tsl.resample(freq).mean()\n",
    "    \n",
    "    # get raw ERA5-Land forcing\n",
    "    meteo = read_meteo(rgi_id)\n",
    "    \n",
    "    # resample to specific frequency\n",
    "    meteo_resample = pd.DataFrame({'t2m_min'  : meteo['t2m_min'].resample(freq).min(), \n",
    "                                   't2m_max'  : meteo['t2m_max'].resample(freq).max(), \n",
    "                                   't2m_mean' : meteo['t2m_mean'].resample(freq).mean(), \n",
    "                                   'd2m'      : meteo['d2m'].resample(freq).mean(),\n",
    "                                   \n",
    "                                   'sp'       : meteo['sp'].resample(freq).mean(),\n",
    "                                   \n",
    "                                   'tp'       : meteo['tp'].resample(freq).sum(),\n",
    "                                   'sf'       : meteo['sf'].resample(freq).sum(),\n",
    "                                   \n",
    "                                   'ssrd_mean': meteo['ssrd_mean'].resample(freq).sum(), \n",
    "                                   'strd_mean': meteo['strd_mean'].resample(freq).sum(),\n",
    "                                   \n",
    "                                    \n",
    "                                   'wind_mean': meteo['wind_mean'].resample(freq).mean(), \n",
    "                                   'wind_dir_mean': meteo['wind_dir_mean'].resample(freq).mean(),\n",
    "                                   })\n",
    "    \n",
    "    if only_t2m_mean:\n",
    "        meteo_resample = meteo_resample.drop(['t2m_min', 't2m_max'], axis=1)\n",
    "    \n",
    "    core_meteo_features = meteo_resample.columns.tolist()\n",
    "    \n",
    "    # enrich meteo features\n",
    "    if freq == \"M\":\n",
    "        meteo_enrich = create_features(meteo_resample, back_to=12)\n",
    "    elif freq == \"W\":\n",
    "        meteo_enrich = create_features(meteo_resample, back_to=48) #12 months back considering 4 weeks in each month\n",
    "    \n",
    "    \n",
    "    # meteo for the entire period\n",
    "    # for model evaluation\n",
    "    meteo_full = meteo_enrich.dropna()\n",
    "    \n",
    "    # merge datasets\n",
    "    dataset = pd.concat([tsl_resample, meteo_enrich], axis=1)\n",
    "    \n",
    "    # drop NaNs\n",
    "    dataset = dataset.dropna()\n",
    "    \n",
    "    if subset_jjas:\n",
    "        dataset = dataset[(dataset.index.month == 6) | (dataset.index.month == 7) | \n",
    "                          (dataset.index.month == 8) | (dataset.index.month == 9)]\n",
    "    \n",
    "    return dataset, meteo_full, core_meteo_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiny_prep(df):\n",
    "       \n",
    "    df_X = df.drop([\"TSL_m\"], axis=1)\n",
    "    df_y = df[\"TSL_m\"]\n",
    "    \n",
    "    return df_X, df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_importances(imp_instance, core_features):\n",
    "    \n",
    "    cols = imp_instance.columns.tolist()\n",
    "    \n",
    "    core_feature_cols = {key: [i for i in cols if key in i] for key in core_features}\n",
    "    \n",
    "    \"\"\"\n",
    "    # temperature-based\n",
    "    t2m_min_cols = [i for i in cols if \"t2m_min\" in i]\n",
    "    t2m_max_cols = [i for i in cols if \"t2m_max\" in i]\n",
    "    t2m_mean_cols = [i for i in cols if \"t2m_mean\" in i]\n",
    "    \n",
    "    # precipitation-based\n",
    "    tp_cols = [i for i in cols if \"tp\" in i]\n",
    "    sf_cols = [i for i in cols if \"sf\" in i]\n",
    "    \n",
    "    # surface solar radiation downwards\n",
    "    ssrd_cols = [i for i in cols if \"ssrd\" in i]\n",
    "    \n",
    "    # surface thermal radiation downwards\n",
    "    strd_cols = [i for i in cols if \"strd\" in i]\n",
    "    \n",
    "    # wind-based\n",
    "    wind_max_cols = [i for i in cols if \"wind_max\" in i]\n",
    "    wind_mean_cols = [i for i in cols if \"wind_mean\" in i]\n",
    "    wind_dir_mean_cols = [i for i in cols if \"wind_dir_mean\" in i]\n",
    "    \n",
    "    # total cloud cover\n",
    "    tcc_cols = [i for i in cols if \"tcc\" in i]\n",
    "    \"\"\"\n",
    "    var_importances = []\n",
    "    \n",
    "    \"\"\"\n",
    "    for var in [t2m_min_cols, \n",
    "                t2m_max_cols, \n",
    "                t2m_mean_cols, \n",
    "                tp_cols, \n",
    "                sf_cols,\n",
    "                ssrd_cols, \n",
    "                strd_cols, \n",
    "                wind_max_cols, \n",
    "                wind_mean_cols, \n",
    "                wind_dir_mean_cols,\n",
    "                tcc_cols]:\n",
    "    \"\"\"    \n",
    "    for var in core_feature_cols.values():\n",
    "        \n",
    "        var_importances.append(imp_instance[var].sum(axis=0).sum())\n",
    "        \n",
    "    var_importances = np.array(var_importances)\n",
    "    \n",
    "    var_importances = var_importances / var_importances.sum()\n",
    "    \n",
    "    return var_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_me(rgi_id, freq, subset_jjas, only_t2m_mean):\n",
    "    \n",
    "    # data: features and target\n",
    "    df, meteo_full, core_features = datasets_construction(rgi_id, freq, subset_jjas, only_t2m_mean)\n",
    "    \n",
    "    features_df, target_df = tiny_prep(df)\n",
    "    features, target = features_df.values, target_df.values \n",
    "    \n",
    "    # model: RandomForest for regression\n",
    "    # parsimonious model with low complexity\n",
    "    # n_estimators is better to be multiple of available CPU threads\n",
    "    model = RandomForestRegressor(random_state=76, n_estimators=n_trees, n_jobs=-1) #N_ESTIMATORS\n",
    "    \n",
    "    # holders for each step predictions/observations\n",
    "    obs = []\n",
    "    prd = []\n",
    "    \n",
    "    # leave-one-out cross-validation\n",
    "    loo = LeaveOneOut()\n",
    "    \n",
    "    # predictions for whole interval\n",
    "    full_preds = []\n",
    "    \n",
    "    # feature importances holder\n",
    "    importances = []\n",
    "    \n",
    "        \n",
    "    # training loop\n",
    "    for train, test in loo.split(target): \n",
    "        \n",
    "        # split data on train/test\n",
    "        X_train, y_train, X_test, y_test = features[train], target[train], features[test], target[test]\n",
    "        \n",
    "        # fir data on train\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # calculate test prediction\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # calculate prediction for the entire dataset\n",
    "        full_pred = model.predict(meteo_full.values)\n",
    "        \n",
    "        # add test and predicted values to holders\n",
    "        obs.append(y_test[0])\n",
    "        prd.append(y_pred[0])\n",
    "        full_preds.append(full_pred)\n",
    "                \n",
    "        # get feature importances from native model\n",
    "        fi = model.feature_importances_\n",
    "        \n",
    "        # convert importances to dataframe\n",
    "        fi_df = pd.DataFrame({0: fi}, index=features_df.columns).T\n",
    "        \n",
    "        # collect\n",
    "        importances.append(fi_df)\n",
    "        \n",
    "        # save model instance\n",
    "        pickle.dump(model, open(os.path.join(results_path_models, f\"{rgi_id}_{test}.pkl\"), 'wb'))\n",
    "                  \n",
    "    \n",
    "    # grab predictions together\n",
    "    obs = np.array(obs)\n",
    "    prd = np.array(prd)\n",
    "    \n",
    "    # calculate r2 LOO score\n",
    "    loo_score = r2_score(obs, prd)\n",
    "    loo_score = pd.DataFrame(loo_score, columns=['R2'], index=[rgi_id])\n",
    "    # save r2 LOO score\n",
    "    loo_score.to_csv(os.path.join(results_path_simulations, f\"{rgi_id}_r2.csv\"),\n",
    "                     compression=\"gzip\")\n",
    "    \n",
    "    # grab loo obs and preds together\n",
    "    loo_sim = pd.DataFrame({\"obs\": obs, \"sim\": prd}, index=features_df.index)\n",
    "    # save loo predicitions\n",
    "    loo_sim.to_csv(os.path.join(results_path_simulations, f\"{rgi_id}_loo.csv\"), \n",
    "                   compression=\"gzip\")\n",
    "    \n",
    "    # postprocessing of entire predictions\n",
    "    full_preds = np.array(full_preds).reshape(len(target), -1)\n",
    "    ensemble_mean = full_preds.mean(axis=0)\n",
    "    tsl_for_meteo_full = pd.DataFrame({\"TSL_sim\": ensemble_mean}, index=meteo_full.index)\n",
    "    # save ensemble mean for the entire meteo ts\n",
    "    tsl_for_meteo_full.to_csv(os.path.join(results_path_simulations, f\"{rgi_id}_ens.csv\"), \n",
    "                              compression=\"gzip\")\n",
    "    \n",
    "    # get importances together\n",
    "    all_importances = pd.concat(importances, axis=0, ignore_index=True)\n",
    "    \n",
    "    # calculate relative importances\n",
    "    rel_importances = calculate_importances(all_importances, core_features)\n",
    "    rel_importances = pd.DataFrame(rel_importances.reshape(1,-1), columns=core_features, index=[rgi_id])\n",
    "    \n",
    "    # save relative importances\n",
    "    rel_importances.to_csv(os.path.join(results_path_simulations, f\"{rgi_id}_ri.csv\"),\n",
    "                           compression=\"gzip\")\n",
    "    \n",
    "    return loo_sim, loo_score, rel_importances, tsl_for_meteo_full\n",
    "    #return loo_score, rel_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/28090 RGI60-13.00014 [[-0.2]] wind_dir_mean\n",
      "2/28090 RGI60-13.00015 [[0.36]] t2m_mean\n",
      "3/28090 RGI60-13.00017 [[0.07]] wind_dir_mean\n",
      "CPU times: user 8min 53s, sys: 2.49 s, total: 8min 56s\n",
      "Wall time: 2min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "broken = []\n",
    "\n",
    "for num, idx in enumerate(glacier_ids[:3]):\n",
    "        \n",
    "    try:\n",
    "        individual_loo_sim, \\\n",
    "        individual_loo_score, \\\n",
    "        individual_importances, \\\n",
    "        individual_tsl_simulations = ML_me(rgi_id=idx, \n",
    "                                           freq=freq, \n",
    "                                           subset_jjas=subset_jjas, \n",
    "                                           only_t2m_mean=only_t2m_mean)\n",
    "    \n",
    "    except:\n",
    "        print(idx, \"Warning\")\n",
    "        broken.append(idx)\n",
    "          \n",
    "    print(f\"{num+1}/{len(glacier_ids)}\", \n",
    "          idx, \n",
    "          np.round(individual_loo_score.to_numpy(), 2),  \n",
    "          individual_importances.columns[np.argmax(individual_importances.to_numpy())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
