{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "\n",
    "\n",
    "# temporal resolution: \"W\" for weekly, or \"M\" for monthly\n",
    "freq = \"W\"\n",
    "\n",
    "# The number of decision trees in Random Forest ensemble\n",
    "n_trees = 10 # recommended: 100\n",
    "\n",
    "# to subset only June, July, August, and September: True\n",
    "# to consider all available TSL measurements: False\n",
    "subset_jjas = False\n",
    "\n",
    "# to consider only mean temperature: True\n",
    "# to consider mean, min, max temperatures: False\n",
    "only_t2m_mean = True\n",
    "\n",
    "if freq == \"M\":\n",
    "    freq_prefix = \"monthly\"\n",
    "elif freq == \"W\":\n",
    "    freq_prefix = \"weekly\"\n",
    "\n",
    "if subset_jjas:\n",
    "    subset_prefix = \"JJAS\"\n",
    "else:\n",
    "    subset_prefix = \"full\"\n",
    "\n",
    "# Dir for results\n",
    "results_path = f\"../results/{freq_prefix}_{subset_prefix}_domain/\"\n",
    "results_path_models = f\"../results/{freq_prefix}_{subset_prefix}_domain/trained_models/\"\n",
    "results_path_simulations = f\"../results/{freq_prefix}_{subset_prefix}_domain/simulations/\"\n",
    "\n",
    "if not os.path.exists(results_path):\n",
    "    os.mkdir(results_path)\n",
    "if not os.path.exists(results_path_models):\n",
    "    os.mkdir(results_path_models)\n",
    "if not os.path.exists(results_path_simulations):\n",
    "    os.mkdir(results_path_simulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining sources of data\n",
    "\n",
    "# RGI IDs\n",
    "glacier_ids = np.load(\"../data/misc/glacier_IDs.npy\", allow_pickle=True)\n",
    "\n",
    "# TSLs\n",
    "tsl_store = pd.read_pickle(\"../data/tsl/TSLs.pkl\")\n",
    "\n",
    "# Meteo forcing\n",
    "meteo_path = \"../data/meteo/agg-weekly/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physiographic attributes\n",
    "static_features = pd.read_csv(\"../data/misc/rgi60_Asia.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tsl(rgi_id, store=tsl_store):\n",
    "    \n",
    "    tsl = tsl_store[tsl_store['RGI_ID'] == rgi_id].copy()\n",
    "    \n",
    "    tsl.index = pd.to_datetime(tsl['LS_DATE'])\n",
    "    \n",
    "    tsl = pd.DataFrame(tsl['TSL_m'])    \n",
    "    \n",
    "    return tsl\n",
    "\n",
    "\n",
    "def read_meteo(rgi_id, path=meteo_path):\n",
    "    \n",
    "    meteo = pd.read_hdf(f\"{meteo_path}{rgi_id}.h5\")\n",
    "    meteo.index = pd.to_datetime(meteo['date'])\n",
    "    meteo = meteo.drop(['date', 'wind_dir_mean_labels'], axis=1)\n",
    "    \n",
    "    return meteo\n",
    "\n",
    "\n",
    "def create_features(dataframe, back_to=12):\n",
    "    \n",
    "    # convert circular wind_dir_mean \n",
    "    # to two components of cos() and sin()\n",
    "    # source: https://stats.stackexchange.com/questions/336613/\n",
    "    # regression-using-circular-variable-hour-from-023-as-predictor\n",
    "    \n",
    "    # copy for safety\n",
    "    df = dataframe.copy()\n",
    "    \n",
    "    # create cos() and sin() components\n",
    "    df[\"wind_dir_mean_cos\"] = np.cos(np.deg2rad(df[\"wind_dir_mean\"]))\n",
    "    df[\"wind_dir_mean_sin\"] = np.sin(np.deg2rad(df[\"wind_dir_mean\"]))\n",
    "    \n",
    "    # drop \"wind_dir_mean\"\n",
    "    df = df.drop([\"wind_dir_mean\"], axis=1)\n",
    "    \n",
    "    # make shifts and rolling means\n",
    "    cols = df.columns\n",
    "    for col in cols:\n",
    "        for shift in range(1, back_to+1, 1):\n",
    "            df[\"{}-{}\".format(col, shift)] = df[col].shift(shift).values\n",
    "        for rol in range(1, back_to+1, 1):\n",
    "            df[\"{}rol-{}\".format(col, rol)] = df[col].rolling(window=rol).mean().values\n",
    "    \n",
    "    # delete NaNs\n",
    "    df = df.dropna()\n",
    "       \n",
    "    return df\n",
    "\n",
    "\n",
    "def datasets_construction(rgi_id, freq, subset_jjas, only_t2m_mean):\n",
    "    \n",
    "    # get raw TSL measurements\n",
    "    tsl = read_tsl(rgi_id)\n",
    "    \n",
    "    # resample to specific frequency\n",
    "    tsl_resample = tsl.resample(freq).mean()\n",
    "    \n",
    "    # get raw ERA5-Land forcing\n",
    "    meteo = read_meteo(rgi_id)\n",
    "    \n",
    "    # resample to specific frequency\n",
    "    meteo_resample = pd.DataFrame({'t2m_min'  : meteo['t2m_min'].resample(freq).min(), \n",
    "                                   't2m_max'  : meteo['t2m_max'].resample(freq).max(), \n",
    "                                   't2m_mean' : meteo['t2m_mean'].resample(freq).mean(), \n",
    "                                   'd2m'      : meteo['d2m'].resample(freq).mean(),\n",
    "                                   \n",
    "                                   'sp'       : meteo['sp'].resample(freq).mean(),\n",
    "                                   \n",
    "                                   'tp'       : meteo['tp'].resample(freq).sum(),\n",
    "                                   'sf'       : meteo['sf'].resample(freq).sum(),\n",
    "                                   \n",
    "                                   'ssrd_mean': meteo['ssrd_mean'].resample(freq).sum(), \n",
    "                                   'strd_mean': meteo['strd_mean'].resample(freq).sum(),\n",
    "                                   \n",
    "                                    \n",
    "                                   'wind_mean': meteo['wind_mean'].resample(freq).mean(), \n",
    "                                   'wind_dir_mean': meteo['wind_dir_mean'].resample(freq).mean(),\n",
    "                                   })\n",
    "    \n",
    "    if only_t2m_mean:\n",
    "        meteo_resample = meteo_resample.drop(['t2m_min', 't2m_max'], axis=1)\n",
    "    \n",
    "    core_meteo_features = meteo_resample.columns.tolist()\n",
    "    \n",
    "    # enrich meteo features\n",
    "    if freq == \"M\":\n",
    "        meteo_enrich = create_features(meteo_resample, back_to=12)\n",
    "    elif freq == \"W\":\n",
    "        meteo_enrich = create_features(meteo_resample, back_to=48) #12 months back considering 4 weeks in each month\n",
    "    \n",
    "    \n",
    "    # meteo for the entire period\n",
    "    # for model evaluation\n",
    "    meteo_full = meteo_enrich.dropna()\n",
    "    \n",
    "    # merge datasets\n",
    "    dataset = pd.concat([tsl_resample, meteo_enrich], axis=1)\n",
    "    \n",
    "    # drop NaNs\n",
    "    dataset = dataset.dropna()\n",
    "    \n",
    "    if subset_jjas:\n",
    "        dataset = dataset[(dataset.index.month == 6) | (dataset.index.month == 7) | \n",
    "                          (dataset.index.month == 8) | (dataset.index.month == 9)]\n",
    "    \n",
    "    return dataset, meteo_full, core_meteo_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basin_wise(rgi_id, freq, subset_jjas, only_t2m_mean):\n",
    "    \n",
    "    data, _, core_features = datasets_construction(rgi_id, freq, subset_jjas, only_t2m_mean)\n",
    "        \n",
    "    static_features_slice = static_features[static_features[\"RGIId\"]==rgi_id].copy()\n",
    "    \n",
    "    static_features_slice = static_features_slice[['CenLon', 'CenLat', 'Area', 'Zmin', 'Zmax', 'Zmed', \n",
    "                                                   'Slope', 'Aspect', 'Lmax']].copy()\n",
    "    \n",
    "    for c in static_features_slice.columns:\n",
    "        data[c] = static_features_slice[c].values[0] \n",
    "        \n",
    "    core_features = core_features + static_features_slice.columns.tolist()\n",
    "    \n",
    "    return data, core_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiny_prep(df):\n",
    "       \n",
    "    df_X = df.drop([\"TSL_m\"], axis=1)\n",
    "    df_y = df[\"TSL_m\"]\n",
    "    \n",
    "    return df_X, df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_importances(imp_instance, core_features):\n",
    "    \n",
    "    cols = imp_instance.columns.tolist()\n",
    "    \n",
    "    core_feature_cols = {key: [i for i in cols if key in i] for key in core_features}\n",
    "    \n",
    "    \"\"\"\n",
    "    # temperature-based\n",
    "    t2m_min_cols = [i for i in cols if \"t2m_min\" in i]\n",
    "    t2m_max_cols = [i for i in cols if \"t2m_max\" in i]\n",
    "    t2m_mean_cols = [i for i in cols if \"t2m_mean\" in i]\n",
    "    \n",
    "    # precipitation-based\n",
    "    tp_cols = [i for i in cols if \"tp\" in i]\n",
    "    sf_cols = [i for i in cols if \"sf\" in i]\n",
    "    \n",
    "    # surface solar radiation downwards\n",
    "    ssrd_cols = [i for i in cols if \"ssrd\" in i]\n",
    "    \n",
    "    # surface thermal radiation downwards\n",
    "    strd_cols = [i for i in cols if \"strd\" in i]\n",
    "    \n",
    "    # wind-based\n",
    "    wind_max_cols = [i for i in cols if \"wind_max\" in i]\n",
    "    wind_mean_cols = [i for i in cols if \"wind_mean\" in i]\n",
    "    wind_dir_mean_cols = [i for i in cols if \"wind_dir_mean\" in i]\n",
    "    \n",
    "    # total cloud cover\n",
    "    tcc_cols = [i for i in cols if \"tcc\" in i]\n",
    "    \"\"\"\n",
    "    var_importances = []\n",
    "    \n",
    "    \"\"\"\n",
    "    for var in [t2m_min_cols, \n",
    "                t2m_max_cols, \n",
    "                t2m_mean_cols, \n",
    "                tp_cols, \n",
    "                sf_cols,\n",
    "                ssrd_cols, \n",
    "                strd_cols, \n",
    "                wind_max_cols, \n",
    "                wind_mean_cols, \n",
    "                wind_dir_mean_cols,\n",
    "                tcc_cols]:\n",
    "    \"\"\"    \n",
    "    for var in core_feature_cols.values():\n",
    "        \n",
    "        var_importances.append(imp_instance[var].sum(axis=0).sum())\n",
    "        \n",
    "    var_importances = np.array(var_importances)\n",
    "    \n",
    "    var_importances = var_importances / var_importances.sum()\n",
    "    \n",
    "    return var_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, core_features = basin_wise(\"RGI60-13.00014\", freq, subset_jjas, only_t2m_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSL_m</th>\n",
       "      <th>t2m_mean</th>\n",
       "      <th>d2m</th>\n",
       "      <th>sp</th>\n",
       "      <th>tp</th>\n",
       "      <th>sf</th>\n",
       "      <th>ssrd_mean</th>\n",
       "      <th>strd_mean</th>\n",
       "      <th>wind_mean</th>\n",
       "      <th>wind_dir_mean_cos</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_dir_mean_sinrol-48</th>\n",
       "      <th>CenLon</th>\n",
       "      <th>CenLat</th>\n",
       "      <th>Area</th>\n",
       "      <th>Zmin</th>\n",
       "      <th>Zmax</th>\n",
       "      <th>Zmed</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Lmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1989-08-06</th>\n",
       "      <td>5568.0</td>\n",
       "      <td>269.083557</td>\n",
       "      <td>264.517609</td>\n",
       "      <td>51168.113281</td>\n",
       "      <td>0.163268</td>\n",
       "      <td>0.139850</td>\n",
       "      <td>237.087082</td>\n",
       "      <td>120.036118</td>\n",
       "      <td>1.876868</td>\n",
       "      <td>-0.987759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265044</td>\n",
       "      <td>78.0681</td>\n",
       "      <td>35.5749</td>\n",
       "      <td>0.649</td>\n",
       "      <td>5559</td>\n",
       "      <td>5953</td>\n",
       "      <td>5745</td>\n",
       "      <td>30.2</td>\n",
       "      <td>51</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-04-07</th>\n",
       "      <td>5571.0</td>\n",
       "      <td>253.201050</td>\n",
       "      <td>249.759186</td>\n",
       "      <td>50769.199219</td>\n",
       "      <td>0.013774</td>\n",
       "      <td>0.013236</td>\n",
       "      <td>233.367905</td>\n",
       "      <td>90.768661</td>\n",
       "      <td>2.591038</td>\n",
       "      <td>-0.972666</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.455834</td>\n",
       "      <td>78.0681</td>\n",
       "      <td>35.5749</td>\n",
       "      <td>0.649</td>\n",
       "      <td>5559</td>\n",
       "      <td>5953</td>\n",
       "      <td>5745</td>\n",
       "      <td>30.2</td>\n",
       "      <td>51</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-05-12</th>\n",
       "      <td>5571.0</td>\n",
       "      <td>258.191711</td>\n",
       "      <td>254.732483</td>\n",
       "      <td>50987.050781</td>\n",
       "      <td>0.048553</td>\n",
       "      <td>0.047331</td>\n",
       "      <td>262.753418</td>\n",
       "      <td>96.882195</td>\n",
       "      <td>2.161129</td>\n",
       "      <td>-0.875503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.447250</td>\n",
       "      <td>78.0681</td>\n",
       "      <td>35.5749</td>\n",
       "      <td>0.649</td>\n",
       "      <td>5559</td>\n",
       "      <td>5953</td>\n",
       "      <td>5745</td>\n",
       "      <td>30.2</td>\n",
       "      <td>51</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-09-01</th>\n",
       "      <td>5579.0</td>\n",
       "      <td>270.421265</td>\n",
       "      <td>262.456482</td>\n",
       "      <td>51504.546875</td>\n",
       "      <td>0.111383</td>\n",
       "      <td>0.062296</td>\n",
       "      <td>227.447083</td>\n",
       "      <td>107.406357</td>\n",
       "      <td>1.327983</td>\n",
       "      <td>-0.847400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.418638</td>\n",
       "      <td>78.0681</td>\n",
       "      <td>35.5749</td>\n",
       "      <td>0.649</td>\n",
       "      <td>5559</td>\n",
       "      <td>5953</td>\n",
       "      <td>5745</td>\n",
       "      <td>30.2</td>\n",
       "      <td>51</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992-02-09</th>\n",
       "      <td>5583.0</td>\n",
       "      <td>239.504517</td>\n",
       "      <td>236.343079</td>\n",
       "      <td>49792.695312</td>\n",
       "      <td>0.057578</td>\n",
       "      <td>0.057304</td>\n",
       "      <td>143.100708</td>\n",
       "      <td>63.163300</td>\n",
       "      <td>2.399455</td>\n",
       "      <td>-0.992695</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.490425</td>\n",
       "      <td>78.0681</td>\n",
       "      <td>35.5749</td>\n",
       "      <td>0.649</td>\n",
       "      <td>5559</td>\n",
       "      <td>5953</td>\n",
       "      <td>5745</td>\n",
       "      <td>30.2</td>\n",
       "      <td>51</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 980 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             TSL_m    t2m_mean         d2m            sp        tp        sf  \\\n",
       "1989-08-06  5568.0  269.083557  264.517609  51168.113281  0.163268  0.139850   \n",
       "1991-04-07  5571.0  253.201050  249.759186  50769.199219  0.013774  0.013236   \n",
       "1991-05-12  5571.0  258.191711  254.732483  50987.050781  0.048553  0.047331   \n",
       "1991-09-01  5579.0  270.421265  262.456482  51504.546875  0.111383  0.062296   \n",
       "1992-02-09  5583.0  239.504517  236.343079  49792.695312  0.057578  0.057304   \n",
       "\n",
       "             ssrd_mean   strd_mean  wind_mean  wind_dir_mean_cos  ...  \\\n",
       "1989-08-06  237.087082  120.036118   1.876868          -0.987759  ...   \n",
       "1991-04-07  233.367905   90.768661   2.591038          -0.972666  ...   \n",
       "1991-05-12  262.753418   96.882195   2.161129          -0.875503  ...   \n",
       "1991-09-01  227.447083  107.406357   1.327983          -0.847400  ...   \n",
       "1992-02-09  143.100708   63.163300   2.399455          -0.992695  ...   \n",
       "\n",
       "            wind_dir_mean_sinrol-48   CenLon   CenLat   Area  Zmin  Zmax  \\\n",
       "1989-08-06                -0.265044  78.0681  35.5749  0.649  5559  5953   \n",
       "1991-04-07                -0.455834  78.0681  35.5749  0.649  5559  5953   \n",
       "1991-05-12                -0.447250  78.0681  35.5749  0.649  5559  5953   \n",
       "1991-09-01                -0.418638  78.0681  35.5749  0.649  5559  5953   \n",
       "1992-02-09                -0.490425  78.0681  35.5749  0.649  5559  5953   \n",
       "\n",
       "            Zmed  Slope  Aspect  Lmax  \n",
       "1989-08-06  5745   30.2      51   615  \n",
       "1991-04-07  5745   30.2      51   615  \n",
       "1991-05-12  5745   30.2      51   615  \n",
       "1991-09-01  5745   30.2      51   615  \n",
       "1992-02-09  5745   30.2      51   615  \n",
       "\n",
       "[5 rows x 980 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t2m_mean',\n",
       " 'd2m',\n",
       " 'sp',\n",
       " 'tp',\n",
       " 'sf',\n",
       " 'ssrd_mean',\n",
       " 'strd_mean',\n",
       " 'wind_mean',\n",
       " 'wind_dir_mean',\n",
       " 'CenLon',\n",
       " 'CenLat',\n",
       " 'Area',\n",
       " 'Zmin',\n",
       " 'Zmax',\n",
       " 'Zmed',\n",
       " 'Slope',\n",
       " 'Aspect',\n",
       " 'Lmax']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collections in progress...\n"
     ]
    }
   ],
   "source": [
    "print(\"Data collections in progress...\")\n",
    "\n",
    "data_file = os.path.join(results_path, \"data.csv\")\n",
    "    \n",
    "for i, idx in enumerate(glacier_ids[0:10]):\n",
    "\n",
    "    chunk, _ = basin_wise(idx, freq, subset_jjas, only_t2m_mean)\n",
    "    \n",
    "    if i == 0:\n",
    "        chunk.to_csv(data_file, mode=\"a\", index=False, header=True)\n",
    "    else:\n",
    "        chunk.to_csv(data_file, mode=\"a\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation has been finished.\n"
     ]
    }
   ],
   "source": [
    "print(\"Data preparation has been finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df, y_df = tiny_prep(data)\n",
    "X, y = X_df.to_numpy(), y_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1754, 979), (1754,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: train 0.9863566873706161, test 0.9394068956284933\n",
      "Fold 2: train 0.9879554403103405, test 0.8883329656471487\n",
      "Fold 3: train 0.9861676415086235, test 0.919839167231866\n",
      "Fold 4: train 0.9848355596227674, test 0.9191529317823577\n",
      "Fold 5: train 0.9847864254405201, test 0.9044761637054436\n"
     ]
    }
   ],
   "source": [
    "print(\"Modeling in progress...\")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "importances = []\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # fit model\n",
    "    m = RandomForestRegressor(n_jobs=-1, n_estimators=n_trees, random_state=42).fit(X_train, y_train)\n",
    "    \n",
    "    # save model\n",
    "    pickle.dump(m, open(os.path.join(results_path_models, f\"RF_{i}.pkl\") , \"wb\"))\n",
    "    \n",
    "    # make predictions for the test set\n",
    "    y_test_pred = m.predict(X_test)\n",
    "    \n",
    "    # save predictions for the test test\n",
    "    sim_df = pd.DataFrame({\"TSL_obs\": y_test, \"TSL_sim\": y_test_pred})\n",
    "    sim_df.to_csv(os.path.join(results_path_simulations, f\"RF_{i}.csv\"))    \n",
    "    \n",
    "    # compute scores\n",
    "    train_score = m.score(X_train, y_train)\n",
    "    test_score = m.score(X_test, y_test)\n",
    "    \n",
    "    # add scores to holders\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    print(f\"Fold {i+1}: train {train_score}, test {test_score}\")\n",
    "    \n",
    "    # calculate feature imortances\n",
    "    fi = m.feature_importances_\n",
    "    \n",
    "    # convert importances to dataframe\n",
    "    fi_df = pd.DataFrame({0: fi}, index=X_df.columns).T\n",
    "\n",
    "    # collect\n",
    "    importances.append(fi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI = calculate_importances(pd.concat(importances, axis=0, ignore_index=True), core_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI = pd.DataFrame(FI.reshape(1,-1), columns=core_features, index=['domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI.to_csv(os.path.join(results_path, \"importances.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame({\"Train\": train_scores, \"Test\": test_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_csv(os.path.join(results_path, \"scores.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling has been finished.\n"
     ]
    }
   ],
   "source": [
    "print(\"Modeling has been finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
